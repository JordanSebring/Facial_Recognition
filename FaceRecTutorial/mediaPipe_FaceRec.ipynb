{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bbe68-2a69-40e3-9068-90ec0ed71078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "from keras_facenet import FaceNet\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Load embeddings\n",
    "data = np.load(\"faces_embeddings_done_4classes_new.npz\", allow_pickle=True)\n",
    "X_known, Y_known = data['arr_0'], data['arr_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c02358-001a-485f-9998-a3dd125824a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55924cf6-a807-447e-a558-e710d0ab27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(mp.__version__)           # should say 0.10.15\n",
    "print(dir(mp.tasks.components))            # should include 'python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33cb4c-daeb-4efe-8bfe-40a9428cd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mediapipe.tasks.python.vision.object_detector import ObjectDetector\n",
    "#from mediapipe.tasks.vision.object_detector import ObjectDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ac49d-7237-4916-bfb0-4e0369b531e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mediapipe.tasks import vision\n",
    "# from mediapipe.tasks.python import BaseOptions\n",
    "# from mediapipe.tasks.python.vision.object_detector import ObjectDetector\n",
    "# #from mediapipe.tasks.pythvision.object_detector import ObjectDetectorOptions\n",
    "\n",
    "# from mediapipe.tasks.python.components.processors import running_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a8149-41df-41b9-8afd-25dd9740a08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9400f7-647e-4b84-bf31-ac1b6e4b5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075cf07-bd2a-428a-967e-9c3003500ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = FaceNet()\n",
    "mp_face = mp.solutions.face_detection\n",
    "detector = mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0b2b0-7e71-45ad-97a1-a432360565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "try:\n",
    "    face_img = img_rgb[y1:y2, x1:x2]\n",
    "    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "        label, confidence = recognize(face_img) \n",
    "except Exception as e:\n",
    "    print(\"Recognition error:\", e)\n",
    "person.add_name(label)\n",
    "person.add_confidence(confidence)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef391d2-9942-4518-bdf6-b93c7d1f3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, id, center, name = \"Unknown\", confidence = 0.0):\n",
    "        self.id = id\n",
    "        self.center = center\n",
    "        self.name = name\n",
    "        self.confidence = confidence\n",
    "        \n",
    "\n",
    "    def add_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def add_confidence(self, confidence):\n",
    "        self.confidence = confidence\n",
    "\n",
    "    def add_center(self, center):\n",
    "        self.center = center\n",
    "    \n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_center(self):\n",
    "        return self.center\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_confidence(self):\n",
    "        return self.confidence\n",
    "    \n",
    "\n",
    "#maybe have a check distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387d594-359d-4491-9992-e84f3916fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import streaming_utils_Tut\n",
    "streaming_utils_Tut.getStream(0)\n",
    "\n",
    "cap = streaming_utils_Tut.getStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3db44-fdc6-4dff-aa69-1b71468ae07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to objects\n",
    "# sets stire the ids and the filter we would do the same thing, go through the object's ids and delete if the id is not in the set\n",
    "\n",
    "TrackedPeople = []     # List of dicts tracking face info\n",
    "# list of dicts: [{'id': 0, 'center': (x, y), 'label': \"Jordan\", 'confidence': 0.92}]\n",
    "next_id = 0\n",
    "recognize_count = 0\n",
    "# Distance threshold (in pixels) to consider same face\n",
    "DIST_THRESH = 60\n",
    "frame_count = 0\n",
    "# finds the box for the face and finds the center of the face which is used to\n",
    "# figure out if we are looking at the same person frame by frame without rerecognizing the person\n",
    "def get_center(box, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    x1 = int(box.xmin * w)\n",
    "    y1 = int(box.ymin * h)\n",
    "    x2 = int((box.xmin + box.width) * w)\n",
    "    y2 = int((box.ymin + box.height) * h)\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "    return (x1, y1, x2, y2), (cx, cy)\n",
    "# maybe have if runtime is above 100 ms, make new faces unknown\n",
    "# check match will for each already known person, distance is calculated and compared to our threshold. \n",
    "def check_match(box, center, matched_id, img_rgb):\n",
    "    global next_id\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx, cy = center\n",
    "    label = \"\"\n",
    "    confidence = 0.0\n",
    "    for person in TrackedPeople:\n",
    "        #print(frame_count, person.get_name(), \"1\")\n",
    "        old_cx, old_cy = person.get_center()\n",
    "        dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "        label = \"Detecting...\"\n",
    "        confidence = 0.0\n",
    "        if dist < DIST_THRESH:\n",
    "            matched_ids.add(person.get_id()) #add same id\n",
    "            person.add_center((cx, cy)) #add new center\n",
    "            if frame_count % 15 != 0:\n",
    "                return True\n",
    "\n",
    "            # What if new label is unknown\n",
    "            face_img = img_rgb[y1:y2, x1:x2]\n",
    "            label, confidence, match_index = recognize(face_img)\n",
    "            person.add_name(label)\n",
    "            person.add_confidence(confidence)\n",
    "            return True\n",
    "    # maybe issue with multiple faces popping up when I move too fast can be fixed with looking at num detection\n",
    "    # if num, detections == 1 then maybe \n",
    "    face_img = img_rgb[y1:y2, x1:x2]\n",
    "    label, confidence, match_index = recognize(face_img) \n",
    "    if match_index == -1:\n",
    "        match_index = next_id\n",
    "    person = Person(match_index, (cx, cy), label, confidence)\n",
    "    TrackedPeople.append(person)\n",
    "    matched_ids.add(match_index)\n",
    "    next_id += 1\n",
    "            \n",
    "            \n",
    "    return False\n",
    "\n",
    "def recognize(face_img):\n",
    "    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "        face_img = img_rgb[y1:y2, x1:x2]\n",
    "        face_img = cv2.resize(face_img, (160, 160))\n",
    "        embedding = embedder.embeddings(np.expand_dims(face_img, axis=0))[0]\n",
    "        distances = [cosine(embedding, emb) for emb in X_known]\n",
    "        min_dist = min(distances)\n",
    "        confidence = 1 - min_dist\n",
    "        if(confidence > 0.6):\n",
    "            match_index = distances.index(min_dist)\n",
    "            label = Y_known[match_index]\n",
    "            return label, confidence, match_index\n",
    "\n",
    "    return \"Unknown\", 0.0, -1\n",
    "    \n",
    "\n",
    "# --- Main Loop ---\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.6) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect\n",
    "        results = face_detector.process(img_rgb)\n",
    "\n",
    "        matched_ids = set()\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                box, center = get_center(detection.location_data.relative_bounding_box, img_rgb.shape)\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = center\n",
    "\n",
    "                \n",
    "                Match = check_match(box, center, matched_ids, img_rgb)\n",
    "                \n",
    "\n",
    "        # Remove people not seen this frame (e.g., left frame) \n",
    "        TrackedPeople = [p for p in TrackedPeople if p.get_id() in matched_ids]\n",
    "        print(\"recog\", recognize_count, frame_count)\n",
    "        # Draw boxes and labels\n",
    "        counter = 0\n",
    "        for person in TrackedPeople:\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "            cx, cy = person.get_center()\n",
    "            x1, y1 = cx - 100, cy - 100\n",
    "            x2, y2 = cx + 100, cy + 100\n",
    "            label = person.get_name()\n",
    "            confidence = person.get_confidence()\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647994cb-0074-45a7-8c78-f912d7eec5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to objects\n",
    "# sets stire the ids and the filter we would do the same thing, go through the object's ids and delete if the id is not in the set\n",
    "\n",
    "TrackedPeople = []     # List of dicts tracking face info\n",
    "# list of dicts: [{'id': 0, 'center': (x, y), 'label': \"Jordan\", 'confidence': 0.92}]\n",
    "next_id = 0\n",
    "recognize_count = 0\n",
    "# Distance threshold (in pixels) to consider same face\n",
    "DIST_THRESH = 60\n",
    "frame_count = 0\n",
    "# finds the box for the face and finds the center of the face which is used to\n",
    "# figure out if we are looking at the same person frame by frame without rerecognizing the person\n",
    "def get_center(box, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    x1 = int(box.xmin * w)\n",
    "    y1 = int(box.ymin * h)\n",
    "    x2 = int((box.xmin + box.width) * w)\n",
    "    y2 = int((box.ymin + box.height) * h)\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "    return (x1, y1, x2, y2), (cx, cy)\n",
    "\n",
    "# check match will for each already known person, distance is calculated and compared to our threshold. \n",
    "def check_match(box, center, matched_ids, next_id):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx, cy = center\n",
    "    label = \"\"\n",
    "    confidence = 0.0\n",
    "    for person in TrackedPeople:\n",
    "        #print(frame_count, person.get_name(), \"1\")\n",
    "        old_cx, old_cy = person.get_center()\n",
    "        matched = False\n",
    "        re_recognize = True\n",
    "        dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "        label = \"Detecting...\"\n",
    "        confidence = 0.3\n",
    "        if dist < DIST_THRESH:\n",
    "            matched = True\n",
    "            matched_ids.add(person.get_id()) #add same id\n",
    "            person.add_center((cx, cy)) #add new center\n",
    "            if frame_count % 15 != 0:\n",
    "                re_recognize = False\n",
    "\n",
    "        if matched == True and re_recognize == False:\n",
    "            return True\n",
    "            \n",
    "        \n",
    "\n",
    "        if matched == True and re_recognize == True:\n",
    "            face_img = img_rgb[y1:y2, x1:x2]\n",
    "            #if frame_count % 5 == 0:\n",
    "            if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                label, confidence = recognize(face_img)\n",
    "            person.add_name(label)\n",
    "            person.add_confidence(confidence)\n",
    "            return True\n",
    "\n",
    "    face_img = img_rgb[y1:y2, x1:x2]\n",
    "    #if frame_count % 5 == 0:\n",
    "    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "        label, confidence = recognize(face_img)  \n",
    "    person = Person(next_id, (cx, cy), label, confidence)\n",
    "    TrackedPeople.append(person)\n",
    "    matched_ids.add(next_id)\n",
    "    next_id += 1\n",
    "            \n",
    "            \n",
    "    return False\n",
    "\"\"\"\n",
    "def check_match(box, center, matched_ids):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx, cy = center\n",
    "    \n",
    "    for person in TrackedPeople:\n",
    "        #print(frame_count, person.get_name(), \"1\")\n",
    "        old_cx, old_cy = person.get_center()\n",
    "                    \n",
    "        dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "        label = \"Detecting...\"\n",
    "        confidence = 0.3\n",
    "        if dist < DIST_THRESH:\n",
    "            \n",
    "            matched_ids.add(person.get_id()) #add same id\n",
    "            person.add_center((cx, cy)) #add new center\n",
    "            if frame_count % 15 == 0:\n",
    "                try:\n",
    "                    face_img = img_rgb[y1:y2, x1:x2]\n",
    "                    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                        label, confidence = recognize(face_img) \n",
    "                except Exception as e:\n",
    "                    print(\"Recognition error:\", e)\n",
    "                person.add_name(label)\n",
    "                person.add_confidence(confidence)\n",
    "                \n",
    "            return True\n",
    "    return False\n",
    "\"\"\"\n",
    "def recognize(face_img):\n",
    "    global recognize_count\n",
    "    recognize_count += 1\n",
    "    face_img = cv2.resize(face_img, (160, 160))\n",
    "    embedding = embedder.embeddings(np.expand_dims(face_img, axis=0))[0]\n",
    "    distances = [cosine(embedding, emb) for emb in X_known]\n",
    "    min_dist = min(distances)\n",
    "    confidence = 1 - min_dist\n",
    "    if(confidence > 0.6):\n",
    "        match_index = distances.index(min_dist)\n",
    "        label = Y_known[match_index]\n",
    "    else:\n",
    "        label = \"Unknown\"\n",
    "    return label, confidence\n",
    "    \n",
    "\n",
    "# --- Main Loop ---\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.6) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect\n",
    "        results = face_detector.process(img_rgb)\n",
    "\n",
    "        matched_ids = set()\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                box, center = get_center(detection.location_data.relative_bounding_box, img_rgb.shape)\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = center\n",
    "\n",
    "                \n",
    "                Match = check_match(box, center, matched_ids, next_id)\n",
    "                \n",
    "                \"\"\"\n",
    "                if not Match:\n",
    "                    \n",
    "                    label = \"Detecting...\"\n",
    "                    confidence = 0.0\n",
    "                    face_img = img_rgb[y1:y2, x1:x2]\n",
    "                    #if frame_count % 5 == 0:\n",
    "                    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                        label, confidence = recognize(face_img)\n",
    "                    person = Person(next_id, (cx, cy), label, confidence)\n",
    "                    TrackedPeople.append(person)\n",
    "                    matched_ids.add(next_id)\n",
    "                    next_id += 1\n",
    "                \"\"\"\n",
    "        # Remove people not seen this frame (e.g., left frame) \n",
    "        TrackedPeople = [p for p in TrackedPeople if p.get_id() in matched_ids]\n",
    "        print(\"recog\", recognize_count, frame_count)\n",
    "        # Draw boxes and labels\n",
    "        counter = 0\n",
    "        for person in TrackedPeople:\n",
    "            \n",
    "            cx, cy = person.get_center()\n",
    "            x1, y1 = cx - 100, cy - 100\n",
    "            x2, y2 = cx + 100, cy + 100\n",
    "            label = person.get_name()\n",
    "            confidence = person.get_confidence()\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65551598-469d-47b0-8017-9ffff4183e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TrackedPeople = []     # List of dicts tracking face info\n",
    "# list of dicts: [{'id': 0, 'center': (x, y), 'label': \"Jordan\", 'confidence': 0.92}]\n",
    "next_id = 0\n",
    "\n",
    "# Distance threshold (in pixels) to consider same face\n",
    "DIST_THRESH = 50\n",
    "\n",
    "\n",
    "def get_center(box, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    x1 = int(box.xmin * w)\n",
    "    y1 = int(box.ymin * h)\n",
    "    x2 = int((box.xmin + box.width) * w)\n",
    "    y2 = int((box.ymin + box.height) * h)\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "    return (x1, y1, x2, y2), (cx, cy)\n",
    "\n",
    "\n",
    "# --- Main Loop ---\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.6) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect\n",
    "        results = face_detector.process(img_rgb)\n",
    "\n",
    "        matched_ids = set()\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                box, center = get_center(detection.location_data.relative_bounding_box, img_rgb.shape)\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = center\n",
    "\n",
    "                matched = False\n",
    "                for person in TrackedPeople:\n",
    "                    old_cx, old_cy = person['center']\n",
    "                    dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "                    if dist < DIST_THRESH:\n",
    "                        matched = True\n",
    "                        matched_ids.add(person['id'])\n",
    "\n",
    "                        # Only re-recognize every 5 frames\n",
    "                        if frame_count % 5 == 0:\n",
    "                            try:\n",
    "                                face_img = img_rgb[y1:y2, x1:x2]\n",
    "                                if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                                    face_img = cv2.resize(face_img, (160, 160))\n",
    "                                    embedding = embedder.embeddings(np.expand_dims(face_img, axis=0))[0]\n",
    "                                    distances = [cosine(embedding, emb) for emb in X_known]\n",
    "                                    min_dist = min(distances)\n",
    "                                    match_index = distances.index(min_dist)\n",
    "                                    label = Y_known[match_index] if min_dist < 0.6 else \"Unknown\"\n",
    "                                    confidence = 1 - min_dist\n",
    "                                    person['label'] = label\n",
    "                                    person['confidence'] = confidence\n",
    "                            except Exception as e:\n",
    "                                print(\"Recognition error:\", e)\n",
    "                        person['center'] = (cx, cy)\n",
    "                        break\n",
    "\n",
    "                if not matched:\n",
    "                    label = \"Detecting...\"\n",
    "                    confidence = 0.0\n",
    "                    if frame_count % 5 == 0:\n",
    "                        try:\n",
    "                            face_img = img_rgb[y1:y2, x1:x2]\n",
    "                            if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                                face_img = cv2.resize(face_img, (160, 160))\n",
    "                                embedding = embedder.embeddings(np.expand_dims(face_img, axis=0))[0]\n",
    "                                distances = [cosine(embedding, emb) for emb in X_known]\n",
    "                                min_dist = min(distances)\n",
    "                                match_index = distances.index(min_dist)\n",
    "                                label = Y_known[match_index] if min_dist < 0.6 else \"Unknown\"\n",
    "                                confidence = 1 - min_dist\n",
    "                        except Exception as e:\n",
    "                            print(\"Recognition error:\", e)\n",
    "\n",
    "                    TrackedPeople.append({\n",
    "                        'id': next_id,\n",
    "                        'center': (cx, cy),\n",
    "                        'label': label,\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "                    matched_ids.add(next_id)\n",
    "                    next_id += 1\n",
    "\n",
    "        # Remove people not seen this frame (e.g., left frame)\n",
    "        TrackedPeople = [p for p in TrackedPeople if p['id'] in matched_ids]\n",
    "\n",
    "        # Draw boxes and labels\n",
    "        for person in TrackedPeople:\n",
    "            cx, cy = person['center']\n",
    "            x1, y1 = cx - 100, cy - 100\n",
    "            x2, y2 = cx + 100, cy + 100\n",
    "            label = person['label']\n",
    "            confidence = person['confidence']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6406ffa-e8fb-4acd-bbee-e1d0995f9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing mp's Face detector\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        start_detect = time.time()\n",
    "        results = face_detector.process(img_rgb) #running face detection on the image\n",
    "        end_detect = time.time()\n",
    "        detection_latency_ms = (end_detect - start_detect) * 1000\n",
    "        print(f\"Face detection latency: {detection_latency_ms:.2f} ms\")\n",
    "        if results.detections: # if there are any detections\n",
    "            detection_counter = 0\n",
    "            for detection in results.detections: \n",
    "                \n",
    "                # gets bounding box, normalizes, and coverts to pixel coords\n",
    "                box = detection.location_data.relative_bounding_box \n",
    "                h, w = img_rgb.shape[:2]\n",
    "                x1 = int(box.xmin * w)\n",
    "                y1 = int(box.ymin * h)\n",
    "                x2 = int((box.xmin + box.width) * w)\n",
    "                y2 = int((box.ymin + box.height) * h)\n",
    "                face = img_rgb[y1:y2, x1:x2]\n",
    "                # a safety check for badly cropped faces, might take out \n",
    "                if face.shape[0] > 0 and face.shape[1] > 0:\n",
    "                    # if any errors occurs we basically skip that frame \n",
    "                    \n",
    "                    if frame_count % 5 == 0:\n",
    "                        try:\n",
    "                            \n",
    "                            face = cv2.resize(face, (160, 160))\n",
    "                            #converts the image to 4D [1, 160, 160, 3] and feeds it into FaceNet\n",
    "                            embedding = embedder.embeddings(np.expand_dims(face, axis=0))[0] # Returns the 128D embedding vector for this face\n",
    "                            \n",
    "                            # Match using cosine similarity\n",
    "                            distances = [cosine(embedding, emb) for emb in X_known]\n",
    "                            min_dist = min(distances)\n",
    "                            match_index = distances.index(min_dist)\n",
    "                            label = Y_known[match_index] if min_dist < 0.6 else \"Unknown\"\n",
    "                            \n",
    "                            confidence = 1 - min_dist\n",
    "                            \n",
    "                            People[detection_counter] = (label, confidence)\n",
    "                        except Exception as e:\n",
    "                            print(\"Error processing face:\", e)\n",
    "            \n",
    "                    \n",
    "                    # Draw box + label\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    if People[detection_counter] is not None:\n",
    "                        cv2.putText(frame, f\"{People[detection_counter][0]} ({People[detection_counter][1]:.2f})\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"Detecting...\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                detection_counter = detection_counter + 1\n",
    "        \n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421c070-6688-4e28-80d8-6d7d7caee9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret : if frame is read secessfully \n",
    "\n",
    "# Facenet time is mid 60s ms\n",
    "# mediaPipes face recognition is 7-11 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988be219-32be-4307-9777-dbd6b8c45a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# --- Setup ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_count = 0\n",
    "\n",
    "mp_face = mp.solutions.face_detection\n",
    "embedder = ...        # <- Your FaceNet embedder object\n",
    "X_known = [...]        # <- Your list of known embeddings\n",
    "Y_known = [...]        # <- Corresponding labels\n",
    "\n",
    "TrackedPeople = []     # List of dicts tracking face info\n",
    "next_id = 0\n",
    "\n",
    "# Distance threshold (in pixels) to consider same face\n",
    "DIST_THRESH = 50\n",
    "\n",
    "\n",
    "def get_center(box, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    x1 = int(box.xmin * w)\n",
    "    y1 = int(box.ymin * h)\n",
    "    x2 = int((box.xmin + box.width) * w)\n",
    "    y2 = int((box.ymin + box.height) * h)\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "    return (x1, y1, x2, y2), (cx, cy)\n",
    "\n",
    "\n",
    "# --- Main Loop ---\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect\n",
    "        results = face_detector.process(img_rgb)\n",
    "\n",
    "        matched_ids = set()\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                box, center = get_center(detection.location_data.relative_bounding_box, img_rgb.shape)\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = center\n",
    "\n",
    "                matched = False\n",
    "                for person in TrackedPeople:\n",
    "                    # comparing each known persons detection to\n",
    "                    old_cx, old_cy = person['center']\n",
    "                    dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "                    # if distance of box is close enough to call it the same box\n",
    "                    if dist < DIST_THRESH:\n",
    "                        matched = True\n",
    "                        matched_ids.add(person['id'])\n",
    "\n",
    "                        # Only re-recognize every 5 frames\n",
    "                        if frame_count % 5 == 0:\n",
    "                            try:\n",
    "                                #re recognizes and adds to known label\n",
    "                            except Exception as e:\n",
    "                                print(\"Recognition error:\", e)\n",
    "                        # update center for person every frame\n",
    "                        break\n",
    "                # if distance is too far to call it the same box for any of our tracked faces\n",
    "                if not matched:\n",
    "                    '''\n",
    "                    label = \"Detecting...\" # probably will take out \n",
    "                    confidence = 0.0\n",
    "                    '''\n",
    "                    if frame_count % 5 == 0:\n",
    "                        try:\n",
    "                            face_img = img_rgb[y1:y2, x1:x2]\n",
    "                            if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                                # Re recognize that detection because its most likely a new face\n",
    "                        except Exception as e:\n",
    "                            print(\"Recognition error:\", e)\n",
    "\n",
    "                    TrackedPeople.append({ \n",
    "                        'id': next_id,\n",
    "                        'center': (cx, cy),\n",
    "                        'label': label,\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "                    matched_ids.add(next_id)\n",
    "                    next_id += 1\n",
    "\n",
    "        # Remove people not seen this frame (e.g., left frame)\n",
    "        TrackedPeople = [p for p in TrackedPeople if p['id'] in matched_ids]\n",
    "        # for each p in the list, include p if ...\n",
    "        # Draw boxes and labels\n",
    "        for person in TrackedPeople:\n",
    "            cx, cy = person['center'] \n",
    "            x1, y1 = cx - 50, cy - 50\n",
    "            x2, y2 = cx + 50, cy + 50\n",
    "            label = person['label'] \n",
    "            confidence = person['confidence']\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
