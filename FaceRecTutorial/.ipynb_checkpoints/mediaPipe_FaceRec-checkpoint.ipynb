{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253bbe68-2a69-40e3-9068-90ec0ed71078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 09:30:52.524668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "from keras_facenet import FaceNet\n",
    "from scipy.spatial.distance import cosine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c02358-001a-485f-9998-a3dd125824a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embeddings\n",
    "data = np.load(\"faces_centroids_4classes.npz\", allow_pickle=True)\n",
    "X_known, Y_known = data['arr_0'], data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55924cf6-a807-447e-a558-e710d0ab27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33cb4c-daeb-4efe-8bfe-40a9428cd5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ac49d-7237-4916-bfb0-4e0369b531e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a8149-41df-41b9-8afd-25dd9740a08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9400f7-647e-4b84-bf31-ac1b6e4b5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a075cf07-bd2a-428a-967e-9c3003500ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752154263.951436 7473964 gl_context.cc:357] GL version: 2.1 (2.1 ATI-7.0.3), renderer: AMD Radeon Pro 560X OpenGL Engine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedder = FaceNet()\n",
    "mp_face = mp.solutions.face_detection\n",
    "detector = mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0b2b0-7e71-45ad-97a1-a432360565ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef391d2-9942-4518-bdf6-b93c7d1f3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, id, center, name = \"Unknown\", confidence = 0.0):\n",
    "        self.id = id\n",
    "        self.center = center\n",
    "        self.name = name\n",
    "        self.confidence = confidence\n",
    "        \n",
    "\n",
    "    def add_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def add_confidence(self, confidence):\n",
    "        self.confidence = confidence\n",
    "\n",
    "    def add_center(self, center):\n",
    "        self.center = center\n",
    "    \n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_center(self):\n",
    "        return self.center\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_confidence(self):\n",
    "        return self.confidence\n",
    "    \n",
    "\n",
    "#maybe have a check distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f387d594-359d-4491-9992-e84f3916fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import streaming_utils_Tut\n",
    "streaming_utils_Tut.getStream(0)\n",
    "\n",
    "cap = streaming_utils_Tut.getStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b3db44-fdc6-4dff-aa69-1b71468ae07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752156044.274123 7473964 gl_context.cc:357] GL version: 2.1 (2.1 ATI-7.0.3), renderer: AMD Radeon Pro 560X OpenGL Engine\n",
      "W0000 00:00:1752156044.309015 7508596 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recog 0 1\n",
      "1\n",
      "1 1\n",
      "recog 0 2\n",
      "1\n",
      "1 1\n",
      "recog 0 3\n",
      "1\n",
      "1 1\n",
      "recog 0 4\n",
      "1\n",
      "1 1\n",
      "recog 0 5\n",
      "1\n",
      "1 1\n",
      "recog 0 6\n",
      "1\n",
      "1 1\n",
      "recog 0 7\n",
      "1\n",
      "1 1\n",
      "recog 0 8\n",
      "1\n",
      "1 1\n",
      "recog 0 9\n",
      "1\n",
      "1 1\n",
      "recog 0 10\n",
      "1\n",
      "1 1\n",
      "recog 0 11\n",
      "1\n",
      "1 1\n",
      "recog 0 12\n",
      "1\n",
      "1 1\n",
      "recog 0 13\n",
      "1\n",
      "1 1\n",
      "recog 0 14\n",
      "1\n",
      "1 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "recog 0 15\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 16\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 17\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 18\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 19\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 20\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 21\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 22\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 23\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 24\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 25\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 26\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 27\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 28\n",
      "1\n",
      "2\n",
      "1 2\n",
      "recog 0 29\n",
      "1\n",
      "2\n",
      "1 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "recog 0 30\n",
      "1\n",
      "2\n",
      "3\n",
      "1 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "recog 0 31\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 32\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 33\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 34\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 35\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 36\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 37\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 38\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 39\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 40\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 41\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 42\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 43\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "recog 0 44\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "recog 0 45\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 46\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 47\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 48\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 49\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 50\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 51\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 52\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 53\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 54\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 55\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 56\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 57\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 58\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "recog 0 59\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "recog 0 60\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 61\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 62\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 63\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 64\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 65\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 66\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 67\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 68\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 69\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 70\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 71\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 72\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 73\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "recog 0 74\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "recog 0 75\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "1 7\n",
      "recog 0 76\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#change to objects\n",
    "# sets stire the ids and the filter we would do the same thing, go through the object's ids and delete if the id is not in the set\n",
    "\n",
    "TrackedPeople = []     # List of dicts tracking face info\n",
    "# list of dicts: [{'id': 0, 'center': (x, y), 'label': \"Jordan\", 'confidence': 0.92}]\n",
    "next_id = 0\n",
    "recognize_count = 0\n",
    "# Distance threshold (in pixels) to consider same face\n",
    "DIST_THRESH = 60\n",
    "frame_count = 0\n",
    "# finds the box for the face and finds the center of the face which is used to\n",
    "# figure out if we are looking at the same person frame by frame without rerecognizing the person\n",
    "def get_center(box, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    x1 = int(box.xmin * w)\n",
    "    y1 = int(box.ymin * h)\n",
    "    x2 = int((box.xmin + box.width) * w)\n",
    "    y2 = int((box.ymin + box.height) * h)\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "    return (x1, y1, x2, y2), (cx, cy)\n",
    "# maybe have if runtime is above 100 ms, make new faces unknown\n",
    "# check match will for each already known person, distance is calculated and compared to our threshold. \n",
    "def check_match(box, center, matched_id, img_rgb):\n",
    "    global next_id\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx, cy = center\n",
    "    label = \"\"\n",
    "    confidence = 0.0\n",
    "    PotentialUnknowns = []\n",
    "    for person in TrackedPeople:\n",
    "        #print(frame_count, person.get_name(), \"1\")\n",
    "        old_cx, old_cy = person.get_center()\n",
    "        dist = np.linalg.norm([cx - old_cx, cy - old_cy])\n",
    "        label = \"Detecting...\"\n",
    "        confidence = 0.0\n",
    "        if dist < DIST_THRESH: #returning true helps keep frame rate high by recognitizing up to 1 new person per frame\n",
    "            matched_ids.add(person.get_id()) #add same id\n",
    "            person.add_center((cx, cy)) #add new center\n",
    "            if frame_count % 15 != 0:\n",
    "                return True\n",
    "\n",
    "            # What if new label is unknown\n",
    "            face_img = img_rgb[y1:y2, x1:x2]\n",
    "            label, confidence, match_index = recognize(face_img)\n",
    "            person.add_name(label)\n",
    "            person.add_confidence(confidence)\n",
    "            #change\n",
    "\n",
    "        \n",
    "    # maybe issue with multiple faces popping up when I move too fast can be fixed with looking at num detection\n",
    "    # if num, detections == 1 then maybe \n",
    "    face_img = img_rgb[y1:y2, x1:x2]\n",
    "    label, confidence, match_index = recognize(face_img) \n",
    "    if match_index == -1:\n",
    "        match_index = next_id\n",
    "    person = Person(match_index, (cx, cy), label, confidence)\n",
    "    TrackedPeople.append(person)\n",
    "    matched_ids.add(match_index)\n",
    "    next_id += 1\n",
    "            \n",
    "            \n",
    "    return False\n",
    "\n",
    "\n",
    "def recognize(face_img):\n",
    "    if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "        face_img = img_rgb[y1:y2, x1:x2]\n",
    "        face_img = cv2.resize(face_img, (160, 160))\n",
    "        embedding = embedder.embeddings(np.expand_dims(face_img, axis=0))[0]\n",
    "        distances = [cosine(embedding, emb) for emb in X_known]\n",
    "        min_dist = min(distances)\n",
    "        confidence = 1 - min_dist\n",
    "        if(confidence > 0.6):\n",
    "            match_index = distances.index(min_dist)\n",
    "            label = Y_known[match_index]\n",
    "            return label, confidence, match_index\n",
    "\n",
    "    return \"Unknown\", 0.0, -1\n",
    "\n",
    "\n",
    "# --- Main Loop ---\n",
    "with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.6) as face_detector:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect\n",
    "        results = face_detector.process(img_rgb)\n",
    "\n",
    "        matched_ids = set()\n",
    "        if results.detections:\n",
    "            print(len(results.detections), len(TrackedPeople))\n",
    "            for detection in results.detections:\n",
    "                box, center = get_center(detection.location_data.relative_bounding_box, img_rgb.shape)\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = center\n",
    "\n",
    "                \n",
    "                Match = check_match(box, center, matched_ids, img_rgb)\n",
    "                \n",
    "\n",
    "        # Remove people not seen this frame (e.g., left frame) \n",
    "        TrackedPeople = [p for p in TrackedPeople if p.get_id() in matched_ids]\n",
    "        print(\"recog\", recognize_count, frame_count)\n",
    "        # Draw boxes and labels\n",
    "        counter = 0\n",
    "        for person in TrackedPeople:\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "            cx, cy = person.get_center()\n",
    "            x1, y1 = cx - 100, cy - 100\n",
    "            x2, y2 = cx + 100, cy + 100\n",
    "            label = person.get_name()\n",
    "            confidence = person.get_confidence()\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f}) {person.get_id()}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "            frame,                       # The image to draw on\n",
    "            f\"{label} {person.get_id()}\",            # The text to display\n",
    "            (10, 30 * counter),                    # (x, y) position (top-left corner)\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,   # Font\n",
    "            0.8,                           # Font scale (size)\n",
    "            (0, 255, 0),                 # Color in BGR (green here)\n",
    "            2,                           # Thickness\n",
    "            cv2.LINE_AA                 # Line type for better quality\n",
    "            )\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647994cb-0074-45a7-8c78-f912d7eec5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Tyler\n",
      "Kendall\n",
      "robert_downey\n",
      "Zach\n",
      "John\n",
      "sardor_abdirayimov\n",
      "Pahal\n",
      "jenna_ortega\n",
      "Jordan\n",
      "taylor_swift\n"
     ]
    }
   ],
   "source": [
    "label = Y_known\n",
    "print(len(label))\n",
    "for names in Y_known:\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65551598-469d-47b0-8017-9ffff4183e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6406ffa-e8fb-4acd-bbee-e1d0995f9f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1421c070-6688-4e28-80d8-6d7d7caee9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret : if frame is read secessfully \n",
    "\n",
    "# Facenet time is mid 60s ms\n",
    "# mediaPipes face recognition is 7-11 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988be219-32be-4307-9777-dbd6b8c45a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
